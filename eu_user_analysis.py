import fire
import os
import glob
import json
import re
import pandas as pd
from geotext import GeoText
from configs import *

base_dir = BASE_DIR
feature_dir = os.path.join(base_dir, "user_features")

# ---------------------------------------------------------
# æ¬§æ´²å›½å®¶ï¼ˆåŒ…å«å¤šè¯­è¨€ aliasesï¼‰
# ---------------------------------------------------------
eu_country_aliases = {
    "albania": ["albania", "shqipÃ«ria"],
    "andorra": ["andorra"],
    "austria": ["austria", "Ã¶sterreich"],
    "belarus": ["belarus", "byelorussia"],
    "belgium": ["belgium", "belgique", "belgiÃ«"],
    "bosnia": ["bosnia", "bosnia and herzegovina", "bih"],
    "bulgaria": ["bulgaria"],
    "croatia": ["croatia", "hrvatska"],
    "cyprus": ["cyprus"],
    "czechia": ["czechia", "czech republic", "Äesko", "cesko"],
    "denmark": ["denmark", "danmark"],
    "estonia": ["estonia", "eesti"],
    "finland": ["finland", "suomi"],
    "france": ["france", "francia"],
    "germany": ["germany", "deutschland"],
    "greece": ["greece", "hellas", "ÎµÎ»Î»Î¬Î´Î±"],
    "hungary": ["hungary", "magyarorszÃ¡g"],
    "iceland": ["iceland", "Ã­sland"],
    "ireland": ["ireland", "Ã©ire"],
    "italy": ["italy", "italia"],
    "latvia": ["latvia", "latvija"],
    "liechtenstein": ["liechtenstein"],
    "lithuania": ["lithuania", "lietuvĞ°"],
    "luxembourg": ["luxembourg", "letzebuerg"],
    "malta": ["malta"],
    "moldova": ["moldova"],
    "monaco": ["monaco"],
    "montenegro": ["montenegro"],
    "netherlands": ["netherlands", "holland", "nederland"],
    "north macedonia": ["north macedonia", "makedonija"],
    "norway": ["norway", "norge"],
    "poland": ["poland", "polska"],
    "portugal": ["portugal", "portuguesa"],
    "romania": ["romania", "romÃ¢nia"],
    "russia": ["russia", "Ñ€Ğ¾ÑÑĞ¸Ñ"],
    "san marino": ["san marino"],
    "serbia": ["serbia", "srbija"],
    "slovakia": ["slovakia", "slovensko"],
    "slovenia": ["slovenia", "slovenija"],
    "spain": ["spain", "espaÃ±a", "espana"],
    "sweden": ["sweden", "sverige"],
    "switzerland": ["switzerland", "schweiz", "suisse", "svizzera"],
    "ukraine": ["ukraine", "ÑƒĞºÑ€Ğ°Ñ—Ğ½Ğ°"],
    "united kingdom": ["united kingdom", "uk", "england", "scotland", "wales", "northern ireland", "gb", "britain"]
}

eu_country_names = []
for k in eu_country_aliases.keys():
    eu_country_names.append(k)

# ---------------------------------------------------------
# å›½æ—— emoji â†’ ISO
# ---------------------------------------------------------
eu_country_abbrs = set([
    "AL","AD","AT","BY","BE","BA","BG","HR","CY","CZ","DK","EE","FI","FR","DE","GR",
    "HU","IS","IE","IT","LV","LI","LT","LU","MT","MD","MC","ME","NL","MK","NO","PL",
    "PT","RO","RU","SM","RS","SK","SI","ES","SE","CH","UA","GB","UK"
])

flag_emoji_regex = re.compile("[\U0001F1E6-\U0001F1FF]{2}")


prons = ["her", "she", "he", "him", "his", "they", "them", "bi", "hole", "black", "white", "gender", "fluid"]
# prons = []

strange = [
    "hell",
    "heaven",
    "twitter",
    "tiktok",
    "instagram",
    "facebook",
    "fuck",
    "planet",
    "alien",
    "aliens",
    "earth",
    "emotion",
    "mastodon",
    "ig",
    "tweet",
    "idk",
    "stardew",
    ".com",
    "podcast",
    "mcdonalds",
    "kfc",
    "universe"
]



eu_emojis = [
    "ğŸ‡¦ğŸ‡±",  # Albania
    "ğŸ‡¦ğŸ‡©",  # Andorra
    "ğŸ‡¦ğŸ‡¹",  # Austria
    "ğŸ‡§ğŸ‡¾",  # Belarus
    "ğŸ‡§ğŸ‡ª",  # Belgium
    "ğŸ‡§ğŸ‡¦",  # Bosnia and Herzegovina
    "ğŸ‡§ğŸ‡¬",  # Bulgaria
    "ğŸ‡­ğŸ‡·",  # Croatia
    "ğŸ‡¨ğŸ‡¾",  # Cyprus
    "ğŸ‡¨ğŸ‡¿",  # Czechia
    "ğŸ‡©ğŸ‡°",  # Denmark
    "ğŸ‡ªğŸ‡ª",  # Estonia
    "ğŸ‡«ğŸ‡®",  # Finland
    "ğŸ‡«ğŸ‡·",  # France
    "ğŸ‡©ğŸ‡ª",  # Germany
    "ğŸ‡¬ğŸ‡·",  # Greece
    "ğŸ‡­ğŸ‡º",  # Hungary
    "ğŸ‡®ğŸ‡¸",  # Iceland
    "ğŸ‡®ğŸ‡ª",  # Ireland
    "ğŸ‡®ğŸ‡¹",  # Italy
    "ğŸ‡±ğŸ‡»",  # Latvia
    "ğŸ‡±ğŸ‡®",  # Liechtenstein
    "ğŸ‡±ğŸ‡¹",  # Lithuania
    "ğŸ‡±ğŸ‡º",  # Luxembourg
    "ğŸ‡²ğŸ‡¹",  # Malta
    "ğŸ‡²ğŸ‡©",  # Moldova
    "ğŸ‡²ğŸ‡¨",  # Monaco
    "ğŸ‡²ğŸ‡ª",  # Montenegro
    "ğŸ‡³ğŸ‡±",  # Netherlands
    "ğŸ‡²ğŸ‡°",  # North Macedonia
    "ğŸ‡³ğŸ‡´",  # Norway
    "ğŸ‡µğŸ‡±",  # Poland
    "ğŸ‡µğŸ‡¹",  # Portugal
    "ğŸ‡·ğŸ‡´",  # Romania
    "ğŸ‡·ğŸ‡º",  # Russia
    "ğŸ‡¸ğŸ‡²",  # San Marino
    "ğŸ‡·ğŸ‡¸",  # Serbia
    "ğŸ‡¸ğŸ‡°",  # Slovakia
    "ğŸ‡¸ğŸ‡®",  # Slovenia
    "ğŸ‡ªğŸ‡¸",  # Spain
    "ğŸ‡¸ğŸ‡ª",  # Sweden
    "ğŸ‡¨ğŸ‡­",  # Switzerland
    "ğŸ‡ºğŸ‡¦",  # Ukraine
    "ğŸ‡¬ğŸ‡§",  # United Kingdom
    "ğŸ‡»ğŸ‡¦",  # Vatican City
]

# å¼ºæ¬§æ´²åŸå¸‚ï¼ˆå¼ºåŒ¹é…ï¼‰
# ---------------------------------------------------------
eu_strong_cities = {
    "london", "paris", "berlin", "rome", "madrid", "vienna", "amsterdam", "brussels",
    "stockholm", "copenhagen", "dublin", "oslo", "helsinki",
    "zurich", "geneva", "prague", "budapest", "lisbon", "athens",
    "milan", "barcelona", "munich", "hamburg", "frankfurt",
    "krakow", "vilnius", "riga", "tallinn", "valencia", "manchester", "cambridge", "oxford", "athens", "georgia", "dublin"
}


eu_strong_cities = {c.lower() for c in eu_strong_cities}

# 
non_europe_country_names = [
    "usa",
    "america",
    "united states",
    "afghanistan",
    "algeria",
    "angola",
    "antigua and barbuda",
    "argentina",
    "armenia",
    "australia",
    "azerbaijan",
    "bahamas",
    "bahrain",
    "bangladesh",
    "barbados",
    "belize",
    "benin",
    "bhutan",
    "bolivia",
    "botswana",
    "brazil",
    "brunei",
    "burkina faso",
    "burundi",
    "cabo verde",
    "cambodia",
    "cameroon",
    "canada",
    "central african republic",
    "chad",
    "chile",
    "china",
    "colombia",
    "comoros",
    "congo",
    "costa rica",
    "cuba",
    "democratic republic of the congo",
    "djibouti",
    "dominica",
    "dominican republic",
    "ecuador",
    "egypt",
    "el salvador",
    "equatorial guinea",
    "eritrea",
    "eswatini",
    "ethiopia",
    "fiji",
    "gabon",
    "gambia",
    "georgia",
    "ghana",
    "grenada",
    "guatemala",
    "guinea",
    "guinea-bissau",
    "guyana",
    "haiti",
    "honduras",
    "india",
    "indonesia",
    "iran",
    "iraq",
    "israel",
    "jamaica",
    "japan",
    "jordan",
    "kazakhstan",
    "kenya",
    "kiribati",
    "kuwait",
    "kyrgyzstan",
    "laos",
    "lebanon",
    "lesotho",
    "liberia",
    "libya",
    "madagascar",
    "malawi",
    "malaysia",
    "maldives",
    "mali",
    "marshall islands",
    "mauritania",
    "mauritius",
    "mexico",
    "micronesia",
    "mongolia",
    "morocco",
    "mozambique",
    "myanmar",
    "namibia",
    "nauru",
    "nepal",
    "new zealand",
    "nicaragua",
    "niger",
    "nigeria",
    "north korea",
    "oman",
    "pakistan",
    "palau",
    "palestine",
    "panama",
    "papua new guinea",
    "paraguay",
    "peru",
    "philippines",
    "qatar",
    "rwanda",
    "saint kitts and nevis",
    "saint lucia",
    "saint vincent and the grenadines",
    "samoa",
    "sao tome and principe",
    "saudi arabia",
    "senegal",
    "seychelles",
    "sierra leone",
    "singapore",
    "solomon islands",
    "somalia",
    "south africa",
    "south korea",
    "south sudan",
    "sri lanka",
    "sudan",
    "suriname",
    "syria",
    "taiwan",
    "tajikistan",
    "tanzania",
    "thailand",
    "timor-leste",
    "togo",
    "tonga",
    "trinidad and tobago",
    "tunisia",
    "turkey",
    "turkmenistan",
    "tuvalu",
    "uganda",
    "united arab emirates",
    "uruguay",
    "uzbekistan",
    "vanuatu",
    "venezuela",
    "vietnam",
    "yemen",
    "zambia",
    "zimbabwe",
    "africa",
    "asia",
    "oceania",
    "antarctica",
    "world",
]

non_europe_country_abbrs = [
    "AF","DZ","AO","AG","AR","AM","AU","AZ","BS","BH","BD","BB","BZ","BJ","BT","BO",
    "BW","BR","BN","BF","BI","CV","KH","CM","CA","CF","TD","CL","CN","CO","KM","CG",
    "CR","CU","CD","DJ","DM","DO","EC","EG","SV","GQ","ER","SZ","ET","FJ","GA","GM",
    "GE","GH","GD","GT","GN","GW","GY","HT","HN","IN","ID","IR","IQ","IL","JM","JP",
    "JO","KZ","KE","KI","KW","KG","LA","LB","LS","LR","LY","MG","MW","MY","MV","ML",
    "MH","MR","MU","MX","FM","MN","MA","MZ","MM","NA","NR","NP","NZ","NI","NE","NG",
    "KP","OM","PK","PW","PS","PA","PG","PY","PE","PH","QA","RW","KN","LC","VC","WS",
    "ST","SA","SN","SC","SL","SG","SB","SO","ZA","KR","SS","LK","SD","SR","SY","TW",
    "TJ","TZ","TH","TL","TG","TO","TT","TN","TR","TM","TV","UG","AE","UY","UZ","VU",
    "VE","VN","YE","ZM","ZW",
]

non_europe_country_emojis = [
    "ğŸ‡¦ğŸ‡«","ğŸ‡©ğŸ‡¿","ğŸ‡¦ğŸ‡´","ğŸ‡¦ğŸ‡¬","ğŸ‡¦ğŸ‡·","ğŸ‡¦ğŸ‡²","ğŸ‡¦ğŸ‡º","ğŸ‡¦ğŸ‡¿","ğŸ‡§ğŸ‡¸","ğŸ‡§ğŸ‡­","ğŸ‡§ğŸ‡©","ğŸ‡§ğŸ‡§","ğŸ‡§ğŸ‡¿",
    "ğŸ‡§ğŸ‡¯","ğŸ‡§ğŸ‡¹","ğŸ‡§ğŸ‡´","ğŸ‡§ğŸ‡¼","ğŸ‡§ğŸ‡·","ğŸ‡§ğŸ‡³","ğŸ‡§ğŸ‡«","ğŸ‡§ğŸ‡®","ğŸ‡¨ğŸ‡»","ğŸ‡°ğŸ‡­","ğŸ‡¨ğŸ‡²","ğŸ‡¨ğŸ‡¦","ğŸ‡¨ğŸ‡«",
    "ğŸ‡¹ğŸ‡©","ğŸ‡¨ğŸ‡±","ğŸ‡¨ğŸ‡³","ğŸ‡¨ğŸ‡´","ğŸ‡°ğŸ‡²","ğŸ‡¨ğŸ‡¬","ğŸ‡¨ğŸ‡·","ğŸ‡¨ğŸ‡º","ğŸ‡¨ğŸ‡©","ğŸ‡©ğŸ‡¯","ğŸ‡©ğŸ‡²","ğŸ‡©ğŸ‡´","ğŸ‡ªğŸ‡¨",
    "ğŸ‡ªğŸ‡¬","ğŸ‡¸ğŸ‡»","ğŸ‡¬ğŸ‡¶","ğŸ‡ªğŸ‡·","ğŸ‡¸ğŸ‡¿","ğŸ‡ªğŸ‡¹","ğŸ‡«ğŸ‡¯","ğŸ‡¬ğŸ‡¦","ğŸ‡¬ğŸ‡²","ğŸ‡¬ğŸ‡ª","ğŸ‡¬ğŸ‡­","ğŸ‡¬ğŸ‡©","ğŸ‡¬ğŸ‡¹",
    "ğŸ‡¬ğŸ‡³","ğŸ‡¬ğŸ‡¼","ğŸ‡¬ğŸ‡¾","ğŸ‡­ğŸ‡¹","ğŸ‡­ğŸ‡³","ğŸ‡®ğŸ‡³","ğŸ‡®ğŸ‡©","ğŸ‡®ğŸ‡·","ğŸ‡®ğŸ‡¶","ğŸ‡®ğŸ‡±","ğŸ‡¯ğŸ‡²","ğŸ‡¯ğŸ‡µ","ğŸ‡¯ğŸ‡´",
    "ğŸ‡°ğŸ‡¿","ğŸ‡°ğŸ‡ª","ğŸ‡°ğŸ‡®","ğŸ‡°ğŸ‡¼","ğŸ‡°ğŸ‡¬","ğŸ‡±ğŸ‡¦","ğŸ‡±ğŸ‡§","ğŸ‡±ğŸ‡¸","ğŸ‡±ğŸ‡·","ğŸ‡±ğŸ‡¾","ğŸ‡²ğŸ‡¬","ğŸ‡²ğŸ‡¼","ğŸ‡²ğŸ‡¾",
    "ğŸ‡²ğŸ‡»","ğŸ‡²ğŸ‡±","ğŸ‡²ğŸ‡­","ğŸ‡²ğŸ‡·","ğŸ‡²ğŸ‡º","ğŸ‡²ğŸ‡½","ğŸ‡«ğŸ‡²","ğŸ‡²ğŸ‡³","ğŸ‡²ğŸ‡¦","ğŸ‡²ğŸ‡¿","ğŸ‡²ğŸ‡²","ğŸ‡³ğŸ‡¦","ğŸ‡³ğŸ‡·",
    "ğŸ‡³ğŸ‡µ","ğŸ‡³ğŸ‡¿","ğŸ‡³ğŸ‡®","ğŸ‡³ğŸ‡ª","ğŸ‡³ğŸ‡¬","ğŸ‡°ğŸ‡µ","ğŸ‡´ğŸ‡²","ğŸ‡µğŸ‡°","ğŸ‡µğŸ‡¼","ğŸ‡µğŸ‡¸","ğŸ‡µğŸ‡¦","ğŸ‡µğŸ‡¬","ğŸ‡µğŸ‡¾",
    "ğŸ‡µğŸ‡ª","ğŸ‡µğŸ‡­","ğŸ‡¶ğŸ‡¦","ğŸ‡·ğŸ‡¼","ğŸ‡°ğŸ‡³","ğŸ‡±ğŸ‡¨","ğŸ‡»ğŸ‡¨","ğŸ‡¼ğŸ‡¸","ğŸ‡¸ğŸ‡¹","ğŸ‡¸ğŸ‡¦","ğŸ‡¸ğŸ‡³","ğŸ‡¸ğŸ‡¨","ğŸ‡¸ğŸ‡±",
    "ğŸ‡¸ğŸ‡¬","ğŸ‡¸ğŸ‡§","ğŸ‡¸ğŸ‡´","ğŸ‡¿ğŸ‡¦","ğŸ‡°ğŸ‡·","ğŸ‡¸ğŸ‡¸","ğŸ‡±ğŸ‡°","ğŸ‡¸ğŸ‡©","ğŸ‡¸ğŸ‡·","ğŸ‡¸ğŸ‡¾","ğŸ‡¹ğŸ‡¼","ğŸ‡¹ğŸ‡¯","ğŸ‡¹ğŸ‡¿",
    "ğŸ‡¹ğŸ‡­","ğŸ‡¹ğŸ‡±","ğŸ‡¹ğŸ‡¬","ğŸ‡¹ğŸ‡´","ğŸ‡¹ğŸ‡¹","ğŸ‡¹ğŸ‡³","ğŸ‡¹ğŸ‡·","ğŸ‡¹ğŸ‡²","ğŸ‡¹ğŸ‡»","ğŸ‡ºğŸ‡¬","ğŸ‡¦ğŸ‡ª","ğŸ‡ºğŸ‡¾","ğŸ‡ºğŸ‡¿",
    "ğŸ‡»ğŸ‡º","ğŸ‡»ğŸ‡ª","ğŸ‡»ğŸ‡³","ğŸ‡¾ğŸ‡ª","ğŸ‡¿ğŸ‡²","ğŸ‡¿ğŸ‡¼"
]


def normalize(loc):
    loc = loc.lower().strip()
    loc = loc.replace(",", " ")
    loc = loc.replace(".", " ")
    loc = loc.replace("/", " ")
    loc = loc.replace("-", " ")
    loc = loc.replace("_", " ")
    loc = loc.replace("|", " ")
    # loc = re.sub(r"[^\w\s\-\u0080-\uFFFF]", " ", loc)
    loc = re.sub(r"\s+", " ", loc)
    # æ‰€æœ‰æ•°å­—éƒ½å»æ‰
    loc = re.sub(r"\d+", "", loc)
    # pronséƒ½å»æ‰
    for word in prons:
        if word.lower() in loc:
            loc = loc.replace(word.lower(), "")
    # strange éƒ½å»æ‰
    # for word in strange:
    #     if word.lower() in loc:
    #         loc = loc.replace(word.lower(), "")
    return loc


# ---------------------------------------------------------
# classify location â†’ {strong, weak, non_eu}
# ---------------------------------------------------------
def classify_location(location):
    loc_norm = normalize(location)
    if len(loc_norm) == 0:
        return "non_eu"
    
    for word in strange:
        if word.lower() in loc_norm:
            return "non_eu"
    
    for emoji in eu_emojis:
        if emoji in loc_norm:
            return "eu"
    
    for country in eu_country_names:
        if country.lower() in loc_norm:
            return "eu"
    
    for city in eu_strong_cities:
        if city.lower() in loc_norm:
            return "eu"

    
    for country in non_europe_country_names:
        if country.lower() in loc_norm:
            return "non_eu"
    
    for country in non_europe_country_emojis:
        if country in loc_norm:
            return "non_eu"

    splitted = (
        loc_norm.strip()
        .split(" ")
    )
    for word in splitted:
        if word.lower() in eu_country_abbrs:
            return "eu"
        if word.lower() in non_europe_country_abbrs:
            return "non_eu"
    

    # å¦‚æœæ²¡æœ‰ä»»ä½• Unicode å­—æ¯ï¼Œåˆ™è®¤ä¸ºæ— æ•ˆ
    if not any(ch.isalpha() for ch in loc_norm):
        return "non_eu"

    # 5) GeoText
    try:
        r = GeoText(location).country_mentions
        if r:
            for c in r:
                if normalize(c) in eu_country_abbrs:
                    return "eu"
                if normalize(c) in non_europe_country_abbrs:
                    return "non_eu"
    except:
        pass

    return "undecided"

# ---------------------------------------------------------
def identify_eu_locations():

    with open(os.path.join(base_dir, "non_us_user_analysis.json")) as f:
        data = json.load(f)

    all_locs = set(data["non_us"]) | set(data["not_sure"]) | set(data["undecided"])

    eu = set()
    unknown = set()
    non_eu = set()

    for loc in all_locs:
        if not loc.strip():
            continue

        cls = classify_location(loc)
        if cls == "eu":
            eu.add(loc)
        elif cls == "non_eu":
            non_eu.add(loc)
        else:
            unknown.add(loc)

    result = {
        "eu": list(eu),
        "unknown": list(unknown),
        "non_eu": list(non_eu)
    }

    with open(os.path.join(base_dir, "eu_location_classified.json"), "w") as f:
        json.dump(result, f, indent=2)

    print(f"æ¬§æ´²: {len(eu)}")
    print(f"æœªçŸ¥: {len(unknown)}")
    print(f"éæ¬§æ´²: {len(non_eu)}")

    # sample 100 unknown locations
    import random
    unknown_sample = random.sample(unknown, 100)
    for loc in unknown_sample:
        print(loc)

    return

def merge_and_report():
    with open(os.path.join(base_dir, "eu_location_classified.json"), "r") as f:
        eu_location_classified = json.load(f)

    llm_result = pd.read_parquet(os.path.join("eu_gpt_analysis", "llm_result.parquet"))

    print(llm_result["result"].value_counts())

    eu_locations = set(eu_location_classified["eu"])
    llm_eu_results = llm_result[llm_result["result"] == 1]["location"]
    eu_locations.update(list(llm_eu_results))

    print(f"eu_locations: {len(eu_locations)}")

    non_eu_locations = set(eu_location_classified["non_eu"])
    llm_non_eu_results = llm_result[llm_result["result"] == 2]["location"]
    non_eu_locations.update(list(llm_non_eu_results))

    print(f"non_eu_locations: {len(non_eu_locations)}")

    undecided_locations = set(eu_location_classified["unknown"])
    llm_undecided_results = llm_result[llm_result["result"] == 0]["location"]
    undecided_locations.update(list(llm_undecided_results))

    print(f"undecided_locations: {len(undecided_locations)}")

    result = {
        "eu": list(eu_locations),
        "non_eu": list(non_eu_locations),
        "unknown": list(undecided_locations)
    }

    with open(os.path.join(base_dir, "eu_location_classified.json"), "w") as f:
        json.dump(result, f)


def get_eu_user_ids():
    with open(os.path.join(base_dir, "eu_location_classified.json"), "r") as f:
        eu_location_classified = json.load(f)
        eu_locations = eu_location_classified["eu"]

    all_feature_files = glob.glob(os.path.join(feature_dir, "user-*.parquet"))

    eu_user_ids = set()
    for feature_file in all_feature_files:
        df = pd.read_parquet(feature_file)
        df = df[df["location"].notna()]
        eu_df = df[df["location"].isin(eu_locations)]
        eu_user_ids.update(eu_df["id"].unique())

    print(f"eu_user_ids: {len(eu_user_ids)}")

    with open(os.path.join(base_dir, "eu_user_ids.json"), "w") as f:
        json.dump(list(eu_user_ids), f)


# ---------------------------------------------------------
if __name__ == "__main__":
    fire.Fire({
        "identify": identify_eu_locations,
        "merge": merge_and_report,
        "user": get_eu_user_ids,
    })