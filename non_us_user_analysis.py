import fire

import os
import glob
import json
import re

import pandas as pd
from geotext import GeoText

from configs import *

base_dir = BASE_DIR

profile_dir = PROFILE_DIR

feature_dir = os.path.join(base_dir, "user_features")

states = [
    "Alabama",
    "Alaska",
    "Arizona",
    "Arkansas",
    "California",
    "Colorado",
    "Connecticut",
    "Delaware",
    "Florida",
    "Georgia",
    "Hawaii",
    "Idaho",
    "Illinois",
    "Indiana",
    "Iowa",
    "Kansas",
    "Kentucky",
    "Louisiana",
    "Maine",
    "Maryland",
    "Massachusetts",
    "Michigan",
    "Minnesota",
    "Mississippi",
    "Missouri",
    "Montana",
    "Nebraska",
    "Nevada",
    "New Hampshire",
    "New Jersey",
    "New Mexico",
    "New York",
    "North Carolina",
    "North Dakota",
    "Ohio",
    "Oklahoma",
    "Oregon",
    "Pennsylvania",
    "Rhode Island",
    "South Carolina",
    "South Dakota",
    "Tennessee",
    "Texas",
    "Utah",
    "Vermont",
    "Virginia",
    "Washington",
    "West Virginia",
    "Wisconsin",
    "Wyoming",
    "United States",
    "USA",
]

major_us_cities_100 = [
    "New York",
    "Los Angeles",
    "NY",
    "LA",
    "NYC",
    "Chicago",
    "CHI",
    "Houston",
    "Phoenix",
    "Philadelphia",
    "San Antonio",
    "San Diego",
    "Dallas",
    "San Jose",
    "Austin",
    "Jacksonville",
    "Fort Worth",
    "Columbus",
    "Charlotte",
    "Francisco",
    "Indianapolis",
    "Seattle",
    "Denver",
    "Washington",
    "Boston",
    "El Paso",
    "Nashville",
    "Detroit",
    "Oklahoma",
    "Portland",
    "Las Vegas",
    "Memphis",
    "Louisville",
    "Baltimore",
    "Milwaukee",
    "Minneapolis",
    "Albuquerque",
    "Tucson",
    "Fresno",
    "Mesa",
    "Sacramento",
    "Atlanta",
    "Kansas",
    "Colorado",
    "Omaha",
    "Raleigh",
    "Miami",
    "Long Beach",
    "Virginia",
    "Oakland",
    "Tulsa",
    "Arlington",
    "Tampa",
    "Orleans",
    "Wichita",
    "Cleveland",
    "Bakersfield",
    "Aurora",
    "Anaheim",
    "Honolulu",
    "Santa Ana",
    "Riverside",
    "Corpus Christi",
    "Lexington",
    "Stockton",
    "Henderson",
    "Saint Paul",
    "St. Louis",
    "Cincinnati",
    "Pittsburgh",
    "Greensboro",
    "Anchorage",
    "Plano",
    "Lincoln",
    "Orlando",
    "Irvine",
    "Newark",
    "Toledo",
    "Durham",
    "Chula Vista",
    "Fort Wayne",
    "Jersey City",
    "Petersburg",
    "Pittsburgh",
    "Princeton",
    "Laredo",
    "Madison",
    "Chandler",
    "Buffalo",
    "Lubbock",
    "Scottsdale",
    "Reno",
    "Glendale",
    "Gilbert",
    "Winstonâ€“Salem",
    "North Las Vegas",
    "Norfolk",
    "Chesapeake",
    "Garland",
    "Irving",
    "Hialeah",
    "Fremont",
    "Boise",
    "Richmond",
    "Baton Rouge",
]

country_names = [
    "afghanistan",
    "albania",
    "algeria",
    "andorra",
    "angola",
    "antigua and barbuda",
    "argentina",
    "armenia",
    "australia",
    "austria",
    "azerbaijan",
    "bahamas",
    "bahrain",
    "bangladesh",
    "barbados",
    "belarus",
    "belgium",
    "belize",
    "benin",
    "bhutan",
    "bolivia",
    "bosnia and herzegovina",
    "botswana",
    "brazil",
    "brunei",
    "bulgaria",
    "burkina faso",
    "burundi",
    "cabo verde",
    "cambodia",
    "cameroon",
    "canada",
    "central african republic",
    "chad",
    "chile",
    "china",
    "colombia",
    "comoros",
    "congo",
    "costa rica",
    "croatia",
    "cuba",
    "cyprus",
    "czechia",
    "democratic republic of the congo",
    "denmark",
    "djibouti",
    "dominica",
    "dominican republic",
    "ecuador",
    "egypt",
    "el salvador",
    "equatorial guinea",
    "eritrea",
    "estonia",
    "eswatini",
    "ethiopia",
    "fiji",
    "finland",
    "france",
    "gabon",
    "gambia",
    "georgia",
    "germany",
    "ghana",
    "greece",
    "grenada",
    "guatemala",
    "guinea",
    "guinea-bissau",
    "guyana",
    "haiti",
    "honduras",
    "hungary",
    "iceland",
    "india",
    "indonesia",
    "iran",
    "iraq",
    "ireland",
    "israel",
    "italy",
    "jamaica",
    "japan",
    "jordan",
    "kazakhstan",
    "kenya",
    "kiribati",
    "kuwait",
    "kyrgyzstan",
    "laos",
    "latvia",
    "lebanon",
    "lesotho",
    "liberia",
    "libya",
    "liechtenstein",
    "lithuania",
    "luxembourg",
    "madagascar",
    "malawi",
    "malaysia",
    "maldives",
    "mali",
    "malta",
    "marshall islands",
    "mauritania",
    "mauritius",
    "mexico",
    "micronesia",
    "moldova",
    "monaco",
    "mongolia",
    "montenegro",
    "morocco",
    "mozambique",
    "myanmar",
    "namibia",
    "nauru",
    "nepal",
    "netherlands",
    "new zealand",
    "nicaragua",
    "niger",
    "nigeria",
    "north korea",
    "north macedonia",
    "norway",
    "oman",
    "pakistan",
    "palau",
    "palestine",
    "panama",
    "papua new guinea",
    "paraguay",
    "peru",
    "philippines",
    "poland",
    "portugal",
    "qatar",
    "romania",
    "russia",
    "rwanda",
    "saint kitts and nevis",
    "saint lucia",
    "saint vincent and the grenadines",
    "samoa",
    "san marino",
    "sao tome and principe",
    "saudi arabia",
    "senegal",
    "serbia",
    "seychelles",
    "sierra leone",
    "singapore",
    "slovakia",
    "slovenia",
    "solomon islands",
    "somalia",
    "south africa",
    "south korea",
    "south sudan",
    "spain",
    "sri lanka",
    "sudan",
    "suriname",
    "sweden",
    "switzerland",
    "syria",
    "taiwan",
    "tajikistan",
    "tanzania",
    "thailand",
    "timor-leste",
    "togo",
    "tonga",
    "trinidad and tobago",
    "tunisia",
    "turkey",
    "turkmenistan",
    "tuvalu",
    "uganda",
    "ukraine",
    "united arab emirates",
    "united kingdom",
    "england",
    "uruguay",
    "uzbekistan",
    "vanuatu",
    "vatican city",
    "venezuela",
    "vietnam",
    "yemen",
    "zambia",
    "zimbabwe",
    "africa",
    "asia",
    "europe",
    "oceania",
    "antarctica",
    "world",
    "deutschland",
]

country_abbrs = [
    "AF",
    "AL",
    "DZ",
    "AD",
    "AO",
    "AG",
    "AR",
    "AM",
    "AU",
    "AT",
    "AZ",
    "BS",
    "BH",
    "BD",
    "BB",
    "BY",
    "BE",
    "BZ",
    "BJ",
    "BT",
    "BO",
    "BA",
    "BW",
    "BR",
    "BN",
    "BG",
    "BF",
    "BI",
    "CV",
    "KH",
    "CM",
    "CA",
    "CF",
    "TD",
    "CL",
    "CN",
    "CO",
    "KM",
    "CG",
    "CR",
    "HR",
    "CU",
    "CY",
    "CZ",
    "CD",
    "DK",
    "DJ",
    "DM",
    "DO",
    "EC",
    "EG",
    "SV",
    "GQ",
    "ER",
    "EE",
    "SZ",
    "ET",
    "FJ",
    "FI",
    "FR",
    "GA",
    "GM",
    "GE",
    "DE",
    "GH",
    "GR",
    "GD",
    "GT",
    "GN",
    "GW",
    "GY",
    "HT",
    "HN",
    "HU",
    "IS",
    "IN",
    "ID",
    "IR",
    "IQ",
    "IE",
    "IL",
    "IT",
    "JM",
    "JP",
    "JO",
    "KZ",
    "KE",
    "KI",
    "KW",
    "KG",
    "LA",
    "LV",
    "LB",
    "LS",
    "LR",
    "LY",
    "LI",
    "LT",
    "LU",
    "MG",
    "MW",
    "MY",
    "MV",
    "ML",
    "MT",
    "MH",
    "MR",
    "MU",
    "MX",
    "FM",
    "MD",
    "MC",
    "MN",
    "ME",
    "MA",
    "MZ",
    "MM",
    "NA",
    "NR",
    "NP",
    "NL",
    "NZ",
    "NI",
    "NE",
    "NG",
    "KP",
    "MK",
    "NO",
    "OM",
    "PK",
    "PW",
    "PS",
    "PA",
    "PG",
    "PY",
    "PE",
    "PH",
    "PL",
    "PT",
    "QA",
    "RO",
    "RU",
    "RW",
    "KN",
    "LC",
    "VC",
    "WS",
    "SM",
    "ST",
    "SA",
    "SN",
    "RS",
    "SC",
    "SL",
    "SG",
    "SK",
    "SI",
    "SB",
    "SO",
    "ZA",
    "KR",
    "SS",
    "ES",
    "LK",
    "SD",
    "SR",
    "SE",
    "CH",
    "SY",
    "TW",
    "TJ",
    "TZ",
    "TH",
    "TL",
    "TG",
    "TO",
    "TT",
    "TN",
    "TR",
    "TM",
    "TV",
    "UG",
    "UA",
    "UK",
    "AE",
    "GB",
    "UY",
    "UZ",
    "VU",
    "VA",
    "VE",
    "VN",
    "YE",
    "ZM",
    "ZW",
]

country_emojis = [
    "ğŸ‡¦ğŸ‡«",  # Afghanistan
    "ğŸ‡¦ğŸ‡±",  # Albania
    "ğŸ‡©ğŸ‡¿",  # Algeria
    "ğŸ‡¦ğŸ‡©",  # Andorra
    "ğŸ‡¦ğŸ‡´",  # Angola
    "ğŸ‡¦ğŸ‡¬",  # Antigua and Barbuda
    "ğŸ‡¦ğŸ‡·",  # Argentina
    "ğŸ‡¦ğŸ‡²",  # Armenia
    "ğŸ‡¦ğŸ‡º",  # Australia
    "ğŸ‡¦ğŸ‡¹",  # Austria
    "ğŸ‡¦ğŸ‡¿",  # Azerbaijan
    "ğŸ‡§ğŸ‡¸",  # Bahamas
    "ğŸ‡§ğŸ‡­",  # Bahrain
    "ğŸ‡§ğŸ‡©",  # Bangladesh
    "ğŸ‡§ğŸ‡§",  # Barbados
    "ğŸ‡§ğŸ‡¾",  # Belarus
    "ğŸ‡§ğŸ‡ª",  # Belgium
    "ğŸ‡§ğŸ‡¿",  # Belize
    "ğŸ‡§ğŸ‡¯",  # Benin
    "ğŸ‡§ğŸ‡¹",  # Bhutan
    "ğŸ‡§ğŸ‡´",  # Bolivia
    "ğŸ‡§ğŸ‡¦",  # Bosnia and Herzegovina
    "ğŸ‡§ğŸ‡¼",  # Botswana
    "ğŸ‡§ğŸ‡·",  # Brazil
    "ğŸ‡§ğŸ‡³",  # Brunei
    "ğŸ‡§ğŸ‡¬",  # Bulgaria
    "ğŸ‡§ğŸ‡«",  # Burkina Faso
    "ğŸ‡§ğŸ‡®",  # Burundi
    "ğŸ‡¨ğŸ‡»",  # Cabo Verde
    "ğŸ‡°ğŸ‡­",  # Cambodia
    "ğŸ‡¨ğŸ‡²",  # Cameroon
    "ğŸ‡¨ğŸ‡¦",  # Canada
    "ğŸ‡¨ğŸ‡«",  # Central African Republic
    "ğŸ‡¹ğŸ‡©",  # Chad
    "ğŸ‡¨ğŸ‡±",  # Chile
    "ğŸ‡¨ğŸ‡³",  # China
    "ğŸ‡¨ğŸ‡´",  # Colombia
    "ğŸ‡°ğŸ‡²",  # Comoros
    "ğŸ‡¨ğŸ‡¬",  # Congo
    "ğŸ‡¨ğŸ‡·",  # Costa Rica
    "ğŸ‡­ğŸ‡·",  # Croatia
    "ğŸ‡¨ğŸ‡º",  # Cuba
    "ğŸ‡¨ğŸ‡¾",  # Cyprus
    "ğŸ‡¨ğŸ‡¿",  # Czechia
    "ğŸ‡¨ğŸ‡©",  # Democratic Republic of the Congo
    "ğŸ‡©ğŸ‡°",  # Denmark
    "ğŸ‡©ğŸ‡¯",  # Djibouti
    "ğŸ‡©ğŸ‡²",  # Dominica
    "ğŸ‡©ğŸ‡´",  # Dominican Republic
    "ğŸ‡ªğŸ‡¨",  # Ecuador
    "ğŸ‡ªğŸ‡¬",  # Egypt
    "ğŸ‡¸ğŸ‡»",  # El Salvador
    "ğŸ‡¬ğŸ‡¶",  # Equatorial Guinea
    "ğŸ‡ªğŸ‡·",  # Eritrea
    "ğŸ‡ªğŸ‡ª",  # Estonia
    "ğŸ‡¸ğŸ‡¿",  # Eswatini
    "ğŸ‡ªğŸ‡¹",  # Ethiopia
    "ğŸ‡«ğŸ‡¯",  # Fiji
    "ğŸ‡«ğŸ‡®",  # Finland
    "ğŸ‡«ğŸ‡·",  # France
    "ğŸ‡¬ğŸ‡¦",  # Gabon
    "ğŸ‡¬ğŸ‡²",  # Gambia
    "ğŸ‡¬ğŸ‡ª",  # Georgia
    "ğŸ‡©ğŸ‡ª",  # Germany
    "ğŸ‡¬ğŸ‡­",  # Ghana
    "ğŸ‡¬ğŸ‡·",  # Greece
    "ğŸ‡¬ğŸ‡©",  # Grenada
    "ğŸ‡¬ğŸ‡¹",  # Guatemala
    "ğŸ‡¬ğŸ‡³",  # Guinea
    "ğŸ‡¬ğŸ‡¼",  # Guinea-Bissau
    "ğŸ‡¬ğŸ‡¾",  # Guyana
    "ğŸ‡­ğŸ‡¹",  # Haiti
    "ğŸ‡­ğŸ‡³",  # Honduras
    "ğŸ‡­ğŸ‡º",  # Hungary
    "ğŸ‡®ğŸ‡¸",  # Iceland
    "ğŸ‡®ğŸ‡³",  # India
    "ğŸ‡®ğŸ‡©",  # Indonesia
    "ğŸ‡®ğŸ‡·",  # Iran
    "ğŸ‡®ğŸ‡¶",  # Iraq
    "ğŸ‡®ğŸ‡ª",  # Ireland
    "ğŸ‡®ğŸ‡±",  # Israel
    "ğŸ‡®ğŸ‡¹",  # Italy
    "ğŸ‡¯ğŸ‡²",  # Jamaica
    "ğŸ‡¯ğŸ‡µ",  # Japan
    "ğŸ‡¯ğŸ‡´",  # Jordan
    "ğŸ‡°ğŸ‡¿",  # Kazakhstan
    "ğŸ‡°ğŸ‡ª",  # Kenya
    "ğŸ‡°ğŸ‡®",  # Kiribati
    "ğŸ‡°ğŸ‡¼",  # Kuwait
    "ğŸ‡°ğŸ‡¬",  # Kyrgyzstan
    "ğŸ‡±ğŸ‡¦",  # Laos
    "ğŸ‡±ğŸ‡»",  # Latvia
    "ğŸ‡±ğŸ‡§",  # Lebanon
    "ğŸ‡±ğŸ‡¸",  # Lesotho
    "ğŸ‡±ğŸ‡·",  # Liberia
    "ğŸ‡±ğŸ‡¾",  # Libya
    "ğŸ‡±ğŸ‡®",  # Liechtenstein
    "ğŸ‡±ğŸ‡¹",  # Lithuania
    "ğŸ‡±ğŸ‡º",  # Luxembourg
    "ğŸ‡²ğŸ‡¬",  # Madagascar
    "ğŸ‡²ğŸ‡¼",  # Malawi
    "ğŸ‡²ğŸ‡¾",  # Malaysia
    "ğŸ‡²ğŸ‡»",  # Maldives
    "ğŸ‡²ğŸ‡±",  # Mali
    "ğŸ‡²ğŸ‡¹",  # Malta
    "ğŸ‡²ğŸ‡­",  # Marshall Islands
    "ğŸ‡²ğŸ‡·",  # Mauritania
    "ğŸ‡²ğŸ‡º",  # Mauritius
    "ğŸ‡²ğŸ‡½",  # Mexico
    "ğŸ‡«ğŸ‡²",  # Micronesia
    "ğŸ‡²ğŸ‡©",  # Moldova
    "ğŸ‡²ğŸ‡¨",  # Monaco
    "ğŸ‡²ğŸ‡³",  # Mongolia
    "ğŸ‡²ğŸ‡ª",  # Montenegro
    "ğŸ‡²ğŸ‡¦",  # Morocco
    "ğŸ‡²ğŸ‡¿",  # Mozambique
    "ğŸ‡²ğŸ‡²",  # Myanmar
    "ğŸ‡³ğŸ‡¦",  # Namibia
    "ğŸ‡³ğŸ‡·",  # Nauru
    "ğŸ‡³ğŸ‡µ",  # Nepal
    "ğŸ‡³ğŸ‡±",  # Netherlands
    "ğŸ‡³ğŸ‡¿",  # New Zealand
    "ğŸ‡³ğŸ‡®",  # Nicaragua
    "ğŸ‡³ğŸ‡ª",  # Niger
    "ğŸ‡³ğŸ‡¬",  # Nigeria
    "ğŸ‡°ğŸ‡µ",  # North Korea
    "ğŸ‡²ğŸ‡°",  # North Macedonia
    "ğŸ‡³ğŸ‡´",  # Norway
    "ğŸ‡´ğŸ‡²",  # Oman
    "ğŸ‡µğŸ‡°",  # Pakistan
    "ğŸ‡µğŸ‡¼",  # Palau
    "ğŸ‡µğŸ‡¸",  # Palestine
    "ğŸ‡µğŸ‡¦",  # Panama
    "ğŸ‡µğŸ‡¬",  # Papua New Guinea
    "ğŸ‡µğŸ‡¾",  # Paraguay
    "ğŸ‡µğŸ‡ª",  # Peru
    "ğŸ‡µğŸ‡­",  # Philippines
    "ğŸ‡µğŸ‡±",  # Poland
    "ğŸ‡µğŸ‡¹",  # Portugal
    "ğŸ‡¶ğŸ‡¦",  # Qatar
    "ğŸ‡·ğŸ‡´",  # Romania
    "ğŸ‡·ğŸ‡º",  # Russia
    "ğŸ‡·ğŸ‡¼",  # Rwanda
    "ğŸ‡°ğŸ‡³",  # Saint Kitts and Nevis
    "ğŸ‡±ğŸ‡¨",  # Saint Lucia
    "ğŸ‡»ğŸ‡¨",  # Saint Vincent and the Grenadines
    "ğŸ‡¼ğŸ‡¸",  # Samoa
    "ğŸ‡¸ğŸ‡²",  # San Marino
    "ğŸ‡¸ğŸ‡¹",  # Sao Tome and Principe
    "ğŸ‡¸ğŸ‡¦",  # Saudi Arabia
    "ğŸ‡¸ğŸ‡³",  # Senegal
    "ğŸ‡·ğŸ‡¸",  # Serbia
    "ğŸ‡¸ğŸ‡¨",  # Seychelles
    "ğŸ‡¸ğŸ‡±",  # Sierra Leone
    "ğŸ‡¸ğŸ‡¬",  # Singapore
    "ğŸ‡¸ğŸ‡°",  # Slovakia
    "ğŸ‡¸ğŸ‡®",  # Slovenia
    "ğŸ‡¸ğŸ‡§",  # Solomon Islands
    "ğŸ‡¸ğŸ‡´",  # Somalia
    "ğŸ‡¿ğŸ‡¦",  # South Africa
    "ğŸ‡°ğŸ‡·",  # South Korea
    "ğŸ‡¸ğŸ‡¸",  # South Sudan
    "ğŸ‡ªğŸ‡¸",  # Spain
    "ğŸ‡±ğŸ‡°",  # Sri Lanka
    "ğŸ‡¸ğŸ‡©",  # Sudan
    "ğŸ‡¸ğŸ‡·",  # Suriname
    "ğŸ‡¸ğŸ‡ª",  # Sweden
    "ğŸ‡¨ğŸ‡­",  # Switzerland
    "ğŸ‡¸ğŸ‡¾",  # Syria
    "ğŸ‡¹ğŸ‡¼",  # Taiwan
    "ğŸ‡¹ğŸ‡¯",  # Tajikistan
    "ğŸ‡¹ğŸ‡¿",  # Tanzania
    "ğŸ‡¹ğŸ‡­",  # Thailand
    "ğŸ‡¹ğŸ‡±",  # Timor-Leste
    "ğŸ‡¹ğŸ‡¬",  # Togo
    "ğŸ‡¹ğŸ‡´",  # Tonga
    "ğŸ‡¹ğŸ‡¹",  # Trinidad and Tobago
    "ğŸ‡¹ğŸ‡³",  # Tunisia
    "ğŸ‡¹ğŸ‡·",  # Turkey
    "ğŸ‡¹ğŸ‡²",  # Turkmenistan
    "ğŸ‡¹ğŸ‡»",  # Tuvalu
    "ğŸ‡ºğŸ‡¬",  # Uganda
    "ğŸ‡ºğŸ‡¦",  # Ukraine
    "ğŸ‡¦ğŸ‡ª",  # United Arab Emirates
    "ğŸ‡¬ğŸ‡§",  # United Kingdom
    "ğŸ‡ºğŸ‡¾",  # Uruguay
    "ğŸ‡ºğŸ‡¿",  # Uzbekistan
    "ğŸ‡»ğŸ‡º",  # Vanuatu
    "ğŸ‡»ğŸ‡¦",  # Vatican City
    "ğŸ‡»ğŸ‡ª",  # Venezuela
    "ğŸ‡»ğŸ‡³",  # Vietnam
    "ğŸ‡¾ğŸ‡ª",  # Yemen
    "ğŸ‡¿ğŸ‡²",  # Zambia
    "ğŸ‡¿ğŸ‡¼",  # Zimbabwe
]

state_abbrs = [
    "US",
    "USA",
    "usa",
    "us",
    "AL",
    "AK",
    "AZ",
    "AR",
    "CA",
    "CO",
    "CT",
    "DE",
    "FL",
    "GA",
    "HI",
    "ID",
    "IL",
    "IN",
    "IA",
    "KS",
    "KY",
    "LA",
    "ME",
    "MD",
    "MA",
    "MI",
    "MN",
    "MS",
    "MO",
    "MT",
    "NE",
    "NV",
    "NH",
    "NJ",
    "NM",
    "NY",
    "NYC",
    "NC",
    "ND",
    "OH",
    "OK",
    "OR",
    "PA",
    "RI",
    "SC",
    "SD",
    "TN",
    "TX",
    "UT",
    "VT",
    "VA",
    "WA",
    "WV",
    "WI",
    "WY",
]

prons = ["her", "she", "he", "him", "his", "they", "them"]

strange = [
    "hell",
    "heaven",
    "twitter",
    "tiktok",
    "instagram",
    "facebook",
    "fuck",
    "planet",
    "alien",
    "aliens",
    "earth",
    "emotion",
    "mastodon",
    "ig",
    "tweet",
    "idk",
    "stardew",
    ".com",
    "podcast",
    "mcdonalds",
    "kfc",
]


def gather_all_locations():
    if os.path.exists(os.path.join(base_dir, "all_locations.json")):
        with open(os.path.join(base_dir, "all_locations.json"), "r") as f:
            all_locations = json.load(f)
        return all_locations

    all_locations = set()
    all_feature_files = glob.glob(os.path.join(feature_dir, "user-*.parquet"))

    for feature_file in all_feature_files:
        df = pd.read_parquet(feature_file)
        df = df[df["location"].notna()]
        all_locations.update(df["location"].unique())

    all_locations = list(all_locations)
    print(len(all_locations))

    with open(os.path.join(base_dir, "all_locations.json"), "w") as f:
        json.dump(all_locations, f)

    return all_locations


def test_usaddress():
    all_locations = gather_all_locations()
    for i in range(100):
        location = all_locations[i + 2000]
        if location == "":
            continue
        print(location)

        print(GeoText(location).country_mentions)


def word_freq_analysis(texts):
    """
    æ‰¾åˆ°é«˜é¢‘è¯
    """
    word_freq = {}
    for text in texts:
        for word in text.split(" "):
            if len(word) < 2:
                continue
            if word in word_freq:
                word_freq[word] += 1
            else:
                word_freq[word] = 1

    word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)

    print(word_freq[:100])


def location_identification(location_file: str = None, output_file: str = None):
    if location_file is None:
        all_locations = gather_all_locations()
    else:
        if os.path.exists(location_file):
            with open(location_file, "r") as f:
                all_locations = json.load(f)
        else:
            raise FileNotFoundError(f"Location file {location_file} not found")

    non_us = set()
    us = set()
    not_sure = set()
    undecided = set()
    for location in all_locations:
        if location == "":
            not_sure.add(location)
            continue
        # å¦‚æœæ²¡æœ‰è‹±æ–‡å­—æ¯
        # if not re.search(r"[a-zA-Z]", location):
        #     not_sure.add(location)
        #     continue
        for word in strange: # + prons:
            continue_flag = False
            if word in location.lower():
                not_sure.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue
        for state in states:
            if state.lower() in location.lower():
                us.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue

        for city in major_us_cities_100:
            if city.lower() in location.lower():
                us.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue

        continue_flag = False
        for country in country_names:
            if country.lower() in location.lower():
                non_us.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue

        for emoji in country_emojis:
            if emoji in location:
                non_us.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue

        splitted = (
            location.strip()
            .replace(",", " ")
            .replace(".", " ")
            .replace("/", " ")
            .split(" ")
        )
        for word in splitted:
            if word in state_abbrs:
                us.add(location)
                continue_flag = True
                break
            if word in country_abbrs:
                non_us.add(location)
                continue_flag = True
                break
        if continue_flag:
            continue

        country_result = GeoText(location).country_mentions
        if not country_result:
            undecided.add(location)
        else:
            if "US" in country_result:
                us.add(location)
            else:
                non_us.add(location)

    # éšæœºæ‰“å° undecidedä¸­çš„ä¸€ç™¾ä¸ª
    # print(list(undecided)[:1000])
    # word_freq_analysis(list(undecided))

    print(
        f"non_us: {len(non_us)}, us: {len(us)}, not_sure: {len(not_sure)}, undecided: {len(undecided)}"
    )

    default_output_file = os.path.join(base_dir, "non_us_user_analysis.json")
    if output_file is None:
        output_file = default_output_file
    
    if os.path.exists(default_output_file):
        with open(default_output_file, "r") as f:
            existing_data = json.load(f)
        us_locations = set(existing_data["us"])
        
        # ä½¿ç”¨é›†åˆäº¤é›†æ“ä½œæ‰¾åˆ°éœ€è¦ç§»åŠ¨çš„ä½ç½®ï¼Œé¿å…åœ¨éå†æ—¶ä¿®æ”¹é›†åˆ
        to_move_from_not_sure = not_sure & us_locations
        not_sure -= to_move_from_not_sure
        us |= to_move_from_not_sure
        
        to_move_from_undecided = undecided & us_locations
        undecided -= to_move_from_undecided
        us |= to_move_from_undecided

    with open(output_file, "w") as f:
        json.dump(
            {
                "non_us": list(non_us),
                "us": list(us),
                "not_sure": list(not_sure),
                "undecided": list(undecided),
            },
            f,
        )


def merge_and_report():
    base_dir = "ai_atti"
    gpt_dir = "ai_atti/llm_analysis"
    with open(os.path.join(base_dir, "non_us_user_analysis.json"), "r") as f:
        non_us_user_analysis = json.load(f)

    llm_result = pd.read_parquet(os.path.join(gpt_dir, "llm_result.parquet"))

    print(llm_result["result"].value_counts())
    # 0-not_sure, 1-us, 2-non_us, add the locations to the set

    llm_not_sure_locations = set(llm_result[llm_result["result"] == 0]["location"])
    llm_us_locations = set(llm_result[llm_result["result"] == 1]["location"])
    llm_non_us_locations = set(llm_result[llm_result["result"] == 2]["location"])

    print(
        f"llm_not_sure_locations: {len(llm_not_sure_locations)}, llm_us_locations: {len(llm_us_locations)}, llm_non_us_locations: {len(llm_non_us_locations)}"
    )

    non_us_user_analysis["not_sure"].extend(llm_not_sure_locations)
    non_us_user_analysis["us"].extend(llm_us_locations)
    non_us_user_analysis["non_us"].extend(llm_non_us_locations)

    print(
        f"non_us_user_analysis: {len(non_us_user_analysis['non_us'])}, us: {len(non_us_user_analysis['us'])}, not_sure: {len(non_us_user_analysis['not_sure'])}, undecided: {len(non_us_user_analysis['undecided'])}"
    )

    with open(os.path.join(base_dir, "non_us_user_analysis.json"), "w") as f:
        json.dump(non_us_user_analysis, f)


def get_non_us_user_ids():
    with open(os.path.join(base_dir, "non_us_user_analysis.json"), "r") as f:
        non_us_user_analysis = json.load(f)
        non_us_locations = non_us_user_analysis["non_us"]
        us_locations = non_us_user_analysis["us"]

    all_feature_files = glob.glob(os.path.join(feature_dir, "user-*.parquet"))

    us_user_ids = set()
    non_us_user_ids = set()
    for feature_file in all_feature_files:
        df = pd.read_parquet(feature_file)
        df = df[df["location"].notna()]
        non_us_df = df[df["location"].isin(non_us_locations)]
        non_us_user_ids.update(non_us_df["id"].unique())

        us_df = df[df["location"].isin(us_locations)]
        us_user_ids.update(us_df["id"].unique())

    print(f"non_us_user_ids: {len(non_us_user_ids)}")
    print(f"us_user_ids: {len(us_user_ids)}")

    with open(os.path.join(base_dir, "non_us_user_ids.json"), "w") as f:
        json.dump(list(non_us_user_ids), f)

    with open(os.path.join(base_dir, "us_user_ids.json"), "w") as f:
        json.dump(list(us_user_ids), f)


if __name__ == "__main__":
    fire.Fire(
        {
            "gather": gather_all_locations,
            "test": test_usaddress,
            "identify": location_identification,
            "merge": merge_and_report,
            "user": get_non_us_user_ids,
        }
    )
